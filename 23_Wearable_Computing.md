[Original](http://www.interaction-design.org/encyclopedia/wearable_computing.html)

# 23. ウェアラブルコンピューティング

> 23. Wearable Computing
> Wearable computing is the study or practice of inventing, designing, building, or using miniature body-borne computational and sensory devices. Wearable computers may be worn under, over, or in clothing, or may also be themselves clothes (i.e. "Smart Clothing" (Mann, 1996a)).

ウェアラブルコンピューティングというのは，体に取り付ける用の小型の計算機デバイスやセンサデバイスを発,n,m,明する，デザインする，作る，使うといった取り組みのことです．ウェアラブルコンピュータは，服の上や下，あるいは服の中に取り付けられたり，服自体がウェアラブルコンピュータだったりします (たとえば．． “Smart Clothing” (Mann, 1996a))．

## 23.1 “Bearable”(身につけられる ≒ Wearable)コンピューティング

> 23.1 Bearable Computing
> The field of wearable computing, however, extends beyond "Smart Clothing". The author often uses the term "Body-Borne Computing" or "Bearable Computing" as a substitute for "Wearable Computing" so as to include all manner of technology that is on or in the body, e.g. implantable devices as well as portable devices like smartphones. In fact the word "portable" comes from the French word "porter" which means "to wear".

しかし，ウェアラブルコンピューティングの分野は，実際には“Smart Clothing”(前述)の考え方をさらに拡張した大きなものです．著者(Mann氏)は，“Body-Borne Computing”や“Bearable Computing”といった用語を，ウェアラブルコンピューティングの代替語としてよく用いています．それは，体の表面に取り付けたり体内に埋め込んだりできるデバイス，さらにはスマートフォンのようなポータブルデバイスなどのすべての技術的アプローチをこの分野に含めようとしたためです．実際，“portable”という単語はフランス語の“porter”（“wear”=身につける）に由来しています．

## 23.2 実用上のアプリケーション

> 23.2 Practical Applications
> Applications of body-borne computing include seeing aids for the blind or visually impaired, as well as memory aids to help persons with special needs. The MindMesh, an EEG (ElectroEncephaloGram) based "thinking cap", for example, allows the user to plug various devices into their brain. A blind person can plug in a camera and use it as an "eye".

Body-Borne(身につける) Computingというのは，目の不自由な人々の視覚補助や，一部の特別なニーズをもつ人々の記憶補助なども含みます．たとえば，MindMeshという，脳波計をベースにした“考える帽子”は，ユーザがさまざまなデバイスを自信の脳とつなぐことを可能にします．目の見えない人がそれをカメラと接続することで，カメラを“目”として使うことができるのです．

> Moreover, body-borne computing in the inclusive sense is for everyone, in the form of such applications as wayfinding, and Personal Safety Devices (PSDs). Body-borne computing is already a part of many people's lives, in the form of a smartphone that helps them find their way if they get lost, or helps protect them from danger (e.g. for emergency notification). The next generation of smartphones will be borne by the body in a way that it is always attentive (e.g. that the camera can always "see" one's environment), so that if a person gets lost, the device will help the user "remember" where they are. Additionally, it will function like the "black box" flight recorder on an aircraft, and, in the event of danger, will be able to automatically notify others of the user's physiological state as well as what happened in the environment.

さらに，道案内や防犯デバイスなどの用途も含めた包括的な意味では，Body-Borne Computingは万人向けのものです．道に迷ったときにスマートフォンが道案内をしてくれたり，あるいは緊急時に通報して危険から守ってくれたりといった形で，Body-Borne Computingはすでに多くの人々の生活の一部となっています．次世代のスマートフォンは，身につけて使うタイプのもっと気の利いたものになり(たとえば，カメラが常にユーザの環境を“見続けて”くれるなど)，もしユーザが道に迷った場合には，彼らが今どこにいるのか“思い出す”手伝いをデバイスがしてくれます．さらに，このデバイスはフライトレコーダー(慣用的に“black box”と呼ぶ)にもなり，危険時には，そこで起こった出来事と一緒にユーザの生理状態を自動的に取得して他社に通知することができます．

> Consider, for example, a simple heart monitor that continuously records ECG (ElectroCardioGram) along with video of the environment. This may help physicians correlate heart arrythmia, or other irregularties, with possible envioronmental causes of stress - a physician may be able to see what was happening to the patient at the time a problem was first detected.

たとえば，ユーザの心電情報をビデオ映像とともに記録し続けるシンプルな心拍モニターを考えてみましょう．このデバイスによって医師は，ユーザの不整脈と環境からのストレス要因とを相関づけやすくなります．医師は，患者の身体に異常が検出されたとき，その患者に何がおこっていたのかを知ることができるようになる(かもしれない)のです．

## 23.3 人と機械の相互関係としてのWearable Computing

> 23.3 Wearable computing as a reciprocal relationship between man and machine
> An important distinction between wearable computers and portable computers (handheld and laptop computers for example) is that the goal of wearable computing is to position or contextualize the computer in such a way that the human and computer are inextricably intertwined, so as to achieve Humanistic Intelligence ? i.e. intelligence that arises by having the human being in the feedback loop of the computational process, e.g. Mann 1998.

Wearable ComputerとPortable Computer(たとえばハンドヘルド型やラップトップ型など)との重要な違いは，ウェアラブルコンピューティングが，人間とコンピュータとを密接に絡み合わせることにより，コンピュータに“Humanistic Intelligence”（計算プロセスのフィードバックループの中に生じる，人間が持つような知性 [Mann 1998]）を実現させるという目的をもつ点です．

> An example of Humanistic Intelligence is the wearable face recognizer (Mann 1996) in which the computer takes the form of electric eyeglasses that "see" everything the wearer sees, and therefore the computer can interact serendipitously. A handheld or laptop computer would not provide the same serendipitous or unexpected interaction, whereas the wearable computer can pop-up virtual nametags if it ever "sees" someone its owner knows or ought to know.

Humanistic Intelligenceの一例にwearable face recognizer (Mann 1996)というデバイスがあり，これは眼鏡の形をしたコンピュータがユーザの見ている全てのものをつねに“見て”おり，それによって思いがけないインタラクションを可能にしたものです．ハンドヘルド型やラップトップ型のコンピュータではこのような思いがけないインタラクションを提供することが到底できないのに対し，ウェアラブルコンピュータならば，ユーザが以前から知っている人あるいはこれから知るべき人などを視界にとらえた際に，バーチャルなネームタグを表示させることができます．
> In this sense, wearable computing can be defined as an embodiment of, or an attempt to embody, Humanistic Intelligence. This definition also allows for the possibility of some or all of the technology to be implanted inside the body, thus broadening from "wearable computing" to "bearable computing" (i.e. body-borne computing).

このような観点でいえば，ウェアラブルコンピューティングというのはHumanistic Intelligenceを具現化したもの(あるいは，具体化しようとしているもの)と定義することができます．この定義は，コンピュータが体内に設置されるようなケース，つまりは“wearable computing”から“bearable computing”への拡張も考慮に入れたものです．

> One of the main features of Humanistic Intelligence is constancy of interaction, that the human and computer are inextricably intertwined. This arises from constancy of interaction between the human and computer, i.e. there is no need to turn the device on prior to engaging it (thus, serendipity).

Humanistic Intelligenceの主な特徴のひとつは，インタラクションの恒常性，つまりは人間とコンピュータとが密接に絡み合っているということです．Humanistic Intelligenceは，人間と機械の間のインタラクションの恒常性，たとえばデバイスを使用する際にいちいちスイッチONしなくてよいという点(および，それにより得られる思いがけない体験)によって生じます．

> Another feature of Humanistic Intelligence is the ability to multi-task. It is not necessary for a person to stop what they are doing to use a wearable computer because it is always running in the background, so as to augment or mediate the human's interactions. Wearable computers can be incorporated by the user to act like a prosthetic, thus forming a true extension of the user's mind and body.

Humanistic Intelligenceのもうひとつの特徴は，マルチタスクができるということです．ウェアラブルコンピュータは常にバックグラウンドで動き続けており，人間のインタラクションを増幅・仲介してくれるので，人間がウェアラブルコンピュータを使用する際に現在の作業を止める必要はありません．ウェアラブルコンピュータは義眼，義手のようにユーザと組み合わさり，ユーザの頭脳や身体を本当の意味で拡張することができるのです．

> It is common in the field of Human-Computer I nteraction (HCI) to think of the human and computer as separate entities. The term "Human-Computer Interaction" emphasizes this separateness by treating the human and computer as different entities that interact. However, Humanistic Intelligence theory thinks of the wearer and the computer with its associated input and output facilities not as separate entities, but regards the computer as a second brain and its sensory modalities as additional senses, in which synthetic synesthesia merges with the wearer's senses. In this context, wearable computing has been referred to as a "Sixth Sense" (Mann & Niedzviecki 2001, Mann 2001 and Geary 2002).

Human-Computer Interaction(HCI)の領域では，一般的に，人間とコンピュータとは別々の個体として扱われます．“Human-Computer Interaction”という用語自体が，人間とコンピュータが互いに関係し合う別々の存在であることを表しています．しかしながら，Humanistic Intelligence理論においては，ユーザとコンピュータ，およびそれらをつなぐIOインターフェースをそれぞれ別の個体とは扱わず，コンピュータを第二の脳として，各種センサモダリティを付加的な感覚として，ユーザの合成共感覚がこれらの付加感覚をユーザ本来の感覚とマージするものとして扱っています．こういった文脈で，ウェアラブルコンピューティングは一種の“第六感”であるとみなされています(Mann & Niedzviecki 2001, Mann 2001 and Geary 2002)．

> When a wearable computer functions as a successful embodiment of Humanistic Intelligence, the computer uses the human's mind and body as one of its peripherals, just as the human uses the computer as a peripheral. This reciprocal relationship is at the heart of Humanistic Intelligence (Mann 2001, Mann 1998, and Knight 2000)

ウェアラブルコンピュータの機能をHumanistic Intelligenceの具現化の成功例と考えるならば，コンピュータは人間の頭脳や身体をみずからの周辺機器として扱っていることとなります(人間がコンピュータをみずからの周辺機器として扱うのと同様に)．この相互関係こそが，Humanistic Intelligenceの肝なのです(Mann 2001, Mann 1998, and Knight 2000)．

## 23.4 ウェアラブルコンピューティングの具体例

### 23.4.1 例1 : Augmented Reality (AR)

> Augmented Reality means to super-impose an extra layer on a real-world environment, thereby augmenting it. An ”augmented reality” is thus a view of a physical, real-world environment whose elements are augmented by computer-generated sensory input such as sound, video, graphics or GPS data. One example is the Wikitude application for the iPhone which lets you point your iPhone’s camera at something, which is then “augmented” with information from the Wikipedia (strictly speaking this is a mediated reality because the iPhone actually modifies vision in some ways - even if nothing more than the fact we're seeing with a camera).

“Augmented Reality”(AR,拡張現実感)とは，実世界環境のうえに外部レイヤーを重畳して，実世界を拡張する概念のことを指します．つまり，Augmented Realityとは，実世界環境をコンピュータで処理されたセンサ入力(音や映像，CGやGPSデータなど)によって拡張したものであるといえます．例のひとつとして，Wikitubeというアプリケーションがあり，これはiPhoneのカメラを物体にかざすことでその物体の情報をWikipediaから取得し，“拡張”表示するというものです．ただし厳密にいえば，iPhoneは実際には(たとえカメラ越しに実世界を見ているだけだとしても)視覚情報を改変した形で表示していることになるので，これは“Mediated Reality”という概念にあたります．

![Augmented Reality prototype.](http://www.interaction-design.org/images/encyclopedia/wearable_computing/Augmented_reality_-_heads_up_display_concept_illustrationSmaller.jpg)

Figure 23.1: ARのプロトタイプ

![Photograph of the Head-Up Display taken by a pilot on a McDonnell Douglas F/A-18 Hornet.](http://www.interaction-design.org/images/encyclopedia/wearable_computing/Head-up-display-hangar_illustrationSmaller.jpg)

Figure 23.2: McDonnell Douglas F/A-18 Hornetに搭載された前方表示補助用ディスプレイ(パイロット視点から撮影)

![The glogger.mobi application: Augmented reality 'lined up' with reality.](http://www.interaction-design.org/images/encyclopedia/wearable_computing/augmented_reality_glogger_iphone_illustrationSmaller.jpg)

Figure 23.3: glogger.mobi アプリ: ARにより線が重畳される．

![The Wikitude iphone application.](http://www.interaction-design.org/images/encyclopedia/wearable_computing/augmented_reality_Wikitude_illustrationSmaller.jpg)

Figure 23.4: The WikitudeのiPhoneアプリ

> A concrete example of wearable computing used for augmented reality is Mann's pendant-based camera and projector system for Augmented Reality. The system shown below was completed by Mann in 1998:

ウェアラブルコンピューティングをARに利用した具体例のひとつに，Mannによるペンダント型カメラ＋プロジェクタシステムがあります．
下記のシステムはMannによって1998年に公開されたものです．

![Neckworn self-gesturing webcam and projector system designed and built by Steve Mann in 1998.](http://www.interaction-design.org/images/encyclopedia/wearable_computing/SixthSense_SteveMann_1998_illustrationThreeOnARow.jpg)

Figure 23.5: 首提げ型のwebcam(ジェスチャ取得用)+プロジェクタによるARシステム．開発設計ともにSteve Mann, 1998.

![Closeup of dome pendant showing the laser-based infinite depth-of-focus projector, called an "aremac" (Mann 2001). The laser-based aremac was developed to project onto any 3D surface and does not require any focusing adjustments.](http://www.interaction-design.org/images/encyclopedia/wearable_computing/SixthSense_aremac_in_domewear_illustrationThreeOnARow.jpg)

Figure 23.6: 無限の焦点深度をもつレーザーベースのプロジェクタを搭載した，ドームペンダント型のデバイス，"aremac"のクローズアップ写真(Mann 2001). レーザーベースのaremacは，どんな3次元凹凸をもつ物体にも投影でき，焦点調整も不要なように設計されている．

![Early breadboard prototype of the aremac that Mann developed for the neckworn webcam+projector.](http://www.interaction-design.org/images/encyclopedia/wearable_computing/SixthSense_aremac_on_breadboard_illustrationThreeOnARow.jpg)

Figure 23.7: aremac初期のブレッドボード回路.

>  In Figure 23.5 the wearer is shopping for milk, but this could also have been a more significant purchase like a new car or a house. The wearer's wife, at a remote location, is looking through the camera by way of a projection screen in her living room in another country. She points a laser pointer at the screen, and a vision system in the projector tracks that and remotely operates the aremac in the wearer's necklace. Thus he sees whatever she draws or scribbles on her screen. This scribbling or drawing directly annotates the “reality” that he's experiencing.

Figure 23.5でユーザ(男性)はaremacを用いてミルクの買い物をしていますが，もちろんこれは車や家などのもっと重要な買い物にも使用できます．たとえば，遠く離れた場所にいるユーザの妻が，リビングに置かれたスクリーンを使って，ユーザのカメラに写った映像を見ます．彼女(妻)がレーザーポインタでスクリーンを指すと，システムがポインタの位置をトラッキングして遠隔ユーザのaremacを操作します．すると，彼(ユーザ)は彼女がスクリーンに書いた内容を見ることができます．この直接書くという行為こそが，ユーザの体験している"リアリティ"をよく表しているといえるでしょう．

(to be continued...)